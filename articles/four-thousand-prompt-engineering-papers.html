<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <link rel="stylesheet" href="../styles/main.css">

    <title>AI Under Hood</title>
</head>
<body>
    <div class="content">
        <header class="header-container">
            <span>
                <a href="../index.html">Main</a> Â©&nbsp;Adil Arshidin
            </span>
            <span class="header-container__nav">
                <a href="#">LLM Benchmark</a>&nbsp;Â·
                <a href="../knowledge_base.html">Knowledge Base</a>
            </span>
            <span>
                <a href="">DE ðŸ‡©ðŸ‡ª</a>&nbsp;/
                <a href="">RU ðŸ‡·ðŸ‡º</a>&nbsp;/
                <a href="four-thousand-prompt-engineering-papers.html">EN ðŸ‡¬ðŸ‡§</a>
            </span>
        </header>
        <main class="main-container">
            <article>
                <h3>Inside 4000 cutting-edge papers on Prompt Engineering.</h3>
                <p>This article is a concise transcription of <a href="https://www.youtube.com/watch?v=cMR2c3vQRAc&t">this Youtube video</a>.</p>
                <p>The comprehensive study of 4000 papers was done by experimenting with Claude, ChatGPT and OpenRouter. A total of 600$ (January 2025) was spent.</p>
                <p>The following are the most useful concepts that were extracted from these studies.</p>
                <br>

                <h4>Role-Based Prompting</h4>
                <p>It's important to not only specify the role, but a specific role that can help with the problem at hand.</p>
                <p>For example, we do not prompt: <i>"You are a mathematician."</i> but <i>"You are an expert in linear algebra."</i></p>
                <p>Extension of this would be a MoE (mixture of agents), where the task is split in different steps and each step is assigned to a specific agent role.</p>
                <p>Example:</p>
                <img src="../images/four-thousand-prompt-engineering-papers-1.jpg">
                <br>

                <h4>CauCoT (Causal Chain of Thought)</h4>
                <p>Classic CoT example:</p>
                <img src="../images/four-thousand-prompt-engineering-papers-2.jpg">
                <p>Causal CoT takes the classic approach a step further. Instead of relying on the LLM to create the steps it will go through, you are providing the steps to it.</p>
                <p>Example:</p>
                <img src="../images/four-thousand-prompt-engineering-papers-3.jpg">
                <br>

                <h4>Structured CoT</h4>
                <p>Here we add one more step to the previous technique. Before the main task we ask the LLM to perform a sub-task which is to understand what is needed to complete the main task.</p>
                <p>Example:</p>
                <img src="../images/four-thousand-prompt-engineering-papers-4.jpg">
                <p>And here's the output:</p>
                <p>
                    <ul style="list-style-type: none;">
                        <li>ðŸ”¹ Step 1: Understand the logical structure of each statement</li>
                        <li>ðŸ”¹ Step 2: Understand what the exclusivity constraint implies</li>
                        <li>ðŸ”¹ Step 3: For each person (A, J, M, S), assume they took the candy</li>
                        <li>ðŸ”¹ Step 4: Maintain causal chains explicitly</li>
                        <li>ðŸ”¹ Step 5: Conclude based on elimination and logical necessity</li>
                    </ul>
                </p>
                <p>We can take this output and use pass it futher to the LLM using CauCoT.</p>
                <br>

                <h4>Program of Thoughts CoT</h4>
                <p>This is similar to CauCoT. But, instead of using natural language for solving the task, we ask the LLM to write the code that can be used to assist in the task.</p>
                <p>Example:</p>
                <img src="../images/four-thousand-prompt-engineering-papers-5.jpg">
                <br>

                <h4>Tree of Thought (ToT)</h4>
                <p>This technique expands from the linear CoT to a tree like structure, accounting for several different problem solving ways. It allows the LLM to return to the previous steps and go through another route in case of an error.</p>
                <p>Example:</p>
                <img src="../images/four-thousand-prompt-engineering-papers-6.jpg">
                <br>

                <h4>Contrast Reasoning</h4>
                <p>This method requires us to give the LLM not only the task of finding the correct solution, but also providing it with the additional task of reasoning an incorrect one.</p>
                <p>Generation of the opposite thoughts forces the LLM to focus of providing the correct answer which will definetily differ from incorrect ones.</p>
                <p>Example:</p>
                <img src="../images/four-thousand-prompt-engineering-papers-7.jpg">
                <br>

                <h4>Chain of Draft (CoD)</h4>
                <p>A simplified version of CoT that uses minimal but informative thoughts (about a sentence for a step). The accuracy is on par to the CoT but less tokens are used.</p>
                <p>Example:</p>
                <img src="../images/four-thousand-prompt-engineering-papers-8.jpg">
                <br>

                <h4>Chain of Reasoning (CoR)</h4>
                <p>Here several reasoning paradigms are used: natural languange, algorithmic, symbolic.</p>
                <p>Example:</p>
                <img src="../images/four-thousand-prompt-engineering-papers-9.jpg">
                <br>

                <h4>Self-Refine</h4>
                <p>Self explanatory. We instruct the LLM to evaluate its own answer and reflect on it.</p>
                <p>Example:</p>
                <img src="../images/four-thousand-prompt-engineering-papers-10.jpg">
                <p>Another way is to define the metric which LLM can use to evaluate its confidence.</p>
                <p>Example:</p>
                <img src="../images/four-thousand-prompt-engineering-papers-11.jpg">
                <br>

                <h4>Chain of Verification (CoV)</h4>
                <p>Technique that combines CoT with Self-Refine method.</p>
                <p>Example:</p>
                <img src="../images/four-thousand-prompt-engineering-papers-12.jpg">
                <br>

                <h4>Sandwich Technique</h4>
                <p>The order of the information that LLM receives through the prompt matters. So, the most critical elements should go in the beginning and in the end.</p>
                <p>Example:</p>
                <img src="../images/four-thousand-prompt-engineering-papers-13.jpg">
                <br>

                <h4>Priority Hierarchy</h4>
            </article>
        </main>
    </div>
</body>
</html>