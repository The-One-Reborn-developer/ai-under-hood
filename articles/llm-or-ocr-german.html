<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <link rel="stylesheet" href="../styles/main.css">

    <title>KI Unter Haube</title>
</head>
<body>
    <div class="content">
        <header class="header-container">
            <span>
                <a href="../index-german.html">Startseite</a> Â©&nbsp;Adil Arshidin
            </span>
            <span class="header-container__nav">
                <a href="#">LLM Benchmark</a>&nbsp;Â·
                <a href="../knowledge_base-german.html">Wissensdatenbank</a>
            </span>
            <span>
                <a href="llm-or-ocr-german.html">DE ğŸ‡©ğŸ‡ª</a>&nbsp;/
                <a href="llm-or-ocr-russian.html">RU ğŸ‡·ğŸ‡º</a>&nbsp;/
                <a href="llm-or-ocr.html">EN ğŸ‡¬ğŸ‡§</a>
            </span>
        </header>
        <main class="main-container">
            <article>
                <h3>LLM oder OCR-Modelle?</h3>
                <p>Welches Werkzeug ist das richtige fÃ¼r diese Aufgabe? Das hÃ¤ngt hauptsÃ¤chlich von der Art der Daten ab, die Sie verarbeiten mÃ¶chten.</p>

                <p>Als Beispiel werde ich zwei FÃ¤lle aus meiner Erfahrung verwenden.</p>

                <br>

                <h4>Fall 1: Erkennung von Dokumentfeldern aus digitalen Dateien</h4>

                <p><strong>Was der Kunde benÃ¶tigte:</strong></p>
                <ul>
                    <li>Informationen aus einem Dokument in Form einer Bilddatei (JPEG) extrahieren.</li>
                    <li>Die gesamte Datenextraktions-Pipeline musste lokal ausgefÃ¼hrt werden.</li>
                </ul>

                <p>Das Bild unten ist ein Beispiel fÃ¼r die Art von Dateien, mit denen ich gearbeitet habe. Es handelt sich nicht um eine echte Datei aus dem Fall, aber das Format ist sehr Ã¤hnlich.</p>

                <img src="../images/llm-or-ocr-1.jpg" alt="gescanntes Dokumentbild">

                <p>Ich werde nicht darauf eingehen, wie diese Aufgabe gelÃ¶st wurde, da sie in <a href="ocr-fine-tuning-german.html">diesem Artikel</a> behandelt wird.</p>

                <p>Wir kÃ¶nnen sehen, dass es <strong>keine Verzerrungen</strong> in den Daten gibt. AuÃŸerdem enthÃ¤lt das Bild <strong>keinen zusÃ¤tzlichen Kontext</strong>, der berÃ¼cksichtigt werden mÃ¼sste (mehr dazu spÃ¤ter im Artikel). Daher sollte ein OCR-Modell verwendet werden.</p>

                <br>

                <h4>Fall 2: Erkennung von Dokumentfeldern auf Fotos</h4>

                <p>Einer meiner Kunden entwickelte ein KYC-System, bei dem einer der Schritte darin bestand, Daten aus einem vom Nutzer hochgeladenen Dokumentfoto zu extrahieren.</p>

                <p><strong>Was der Kunde benÃ¶tigte:</strong></p>
                <ul>
                    <li>Informationen aus dem Dokument in Form eines Fotos extrahieren.</li>
                    <li>Zu diesem Zeitpunkt nutzten sie Gemini 1.5 Pro Ã¼ber API-Anfragen. Sie benÃ¶tigten eine lokale LÃ¶sung, vorzugsweise eine, die nicht zu GPU-intensiv war.</li>
                </ul>

                <p>Das folgende Bild ist ein Beispiel fÃ¼r ein vom Nutzer hochgeladenes Foto:</p>

                <img src="../images/llm-or-ocr-2.jpg" alt="Dokumentfoto des Nutzers">

                <p>Wir kÃ¶nnen sofort die potenziellen Probleme erkennen, wenn man versucht, ein solches Bild mit einem OCR-Modell zu verarbeiten.</p>
                <ul>
                    <li>Das Dokument kann deformiert oder nicht klar sichtbar sein (im obigen Beispiel ist es in ein transparentes Material eingeschlossen).</li>
                    <li>Die FotoqualitÃ¤t kann schlecht sein.</li>
                    <li>Andere visuelle Elemente kÃ¶nnten die Aufgabe stÃ¶ren. Zum Beispiel kÃ¶nnte das Dokument auf einem nicht leeren Blatt Papier liegen.</li>
                    <li>Die Nutzer senden nicht immer ideale Fotos. Das Bild kann gedreht, durch den Blitz Ã¼berbelichtet oder teilweise verdeckt sein.</li>
                    <li>Erinnern Sie sich, als ich den Kontext erwÃ¤hnte? In diesem Fall mÃ¼ssen wir nicht nur die Daten extrahieren, sondern auch bewerten, ob das Dokument gefÃ¤lscht, ob Felder fehlen, handgeschrieben oder digital ausgefÃ¼llt ist.</ul>
                </ul>

                <p>In Anbetracht all dieser Punkte ist das LLM hier die bessere Wahl.</p>

                <br>

                <h4>Zusammenfassung</h4>

                <p><strong>Ein OCR-Modell sollte verwendet werden, wenn:</strong></p>
                <ul>
                    <li>Die Bilder sind einheitlich, mit wenig bis keiner Abwechslung in ihrer PrÃ¤sentation.</li>
                    <li>Die einzige Aufgabe ist die Datenextraktion (technisch gesagt, das OCR-Modell kÃ¶nnte Teil eines MoE-Pipelines sein, aber hier wÃ¤hlen wir das Werkzeug, das alle notwendigen Aufgaben abdecken kann).</li>
                </ul>

                <p><strong>Ein LLM sollte verwendet werden, wenn:</strong></p>
                <ul>
                    <li>Die Bilder haben Verzerrungen.</li>
                    <li>Datenextraktion ist nur eine von mehreren benÃ¶tigten Aufgaben.</li>
                </ul>
                </p>
            </article>
        </main>
    </div>
</body>
</html>